{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thread vs process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### process\n",
    "An instance of a program(e.g.python interpreter)\n",
    "###### Advantage\n",
    "* takea advantage of multiple CPU's and cores.\n",
    "* seperate memory space -> memory is not shared between processes.\n",
    "* Great for CPU bound processing.\n",
    "* New process is started independently from other.\n",
    "* Process are interruptable/killable.\n",
    "* one gil for each process(avoids gil limitations.\n",
    "\n",
    "##### Disadvantages-\n",
    "* Heavyweight \n",
    "* starting a process is slower than starting a thread.\n",
    "* more memory.\n",
    "* IPC (inter process communication) is more complicated since memory is not shared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threads-\n",
    "An entity  within a process  that can be  scheduled (also known as lightweight process)\n",
    "A process can spawn multiple threads.\n",
    "##### Advantages\n",
    "* All threads with in a process share the same memory.\n",
    "* Lightweight.\n",
    "* Starting a thread is faster then starting a process.\n",
    "* Great for I/O-bound tasks.\n",
    "##### Disadvantages-\n",
    "* Threading is limited by GIL: Only  one thread at a time.\n",
    "* No effect for CPU-bound tasks.\n",
    "* Not interuptable/killable.\n",
    "* Careful with race conditions.(Race condition occurs when two or more threads want to modify a same variable at the same time.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is GIL?\n",
    "Global interpreter lock.\n",
    "* A lock that allows only one thread a time to execute in python.\n",
    "* needed in Cpython because memory managementis not threaed-safe.\n",
    "##### Solution\n",
    "* use multiprocessing\n",
    "* use a different , free handed python implementation (Jython,IronPython).\n",
    "* USe python as a wrapper for third party libraries(C/C++) ->numpy,scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_it():\n",
    "    for i in range(1000):\n",
    "        i*i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processes = []\n",
    "num_process = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a processes-\n",
    "for i in range(num_process):\n",
    "    p = Process(target=square_it)\n",
    "    processes.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in processes:\n",
    "    i.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are waiting for all process to be finished and block the main thread untill\n",
    "#the process is finish\n",
    "for i in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end main\n"
     ]
    }
   ],
   "source": [
    "print('end main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_it():\n",
    "    for i in range(1000):\n",
    "        i*i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_threads = 10\n",
    "threads = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(number_threads):\n",
    "    t = Thread(target=square_it)\n",
    "    processes.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start-\n",
    "for t in threads:\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we can share data between threads as they share the memory- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase():\n",
    "    global database_value\n",
    "    localcopy = database_value\n",
    "    # processing\n",
    "    localcopy+=1\n",
    "    time.sleep(0.1)\n",
    "    database_value = localcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start value 0\n",
      "end value 1\n",
      "end main\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(f'start value {database_value}')\n",
    "    thread1 = Thread(target=increase)\n",
    "    thread2 = Thread(target=increase)\n",
    "    \n",
    "    thread1.start()\n",
    "    thread2.start()\n",
    "    \n",
    "    thread1.join()\n",
    "    thread2.join()\n",
    "    \n",
    "    print(f'end value {database_value}')\n",
    "    print('end main')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but is it not increased  to 2.\n",
    "#This is because two threds are trying to modify the same variable.\n",
    "# use lock object for this-\n",
    "from threading import Thread,Lock\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase(lock):\n",
    "    global database_value\n",
    "    with lock:\n",
    "        localcopy = database_value\n",
    "        # processing\n",
    "        localcopy+=1\n",
    "        time.sleep(0.1)\n",
    "        database_value = localcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start value 0\n",
      "end value 2\n",
      "end main\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(f'start value {database_value}')\n",
    "    lock = Lock()\n",
    "    thread1 = Thread(target=increase,args=(lock,))\n",
    "    thread2 = Thread(target=increase,args=(lock,))\n",
    "    \n",
    "    thread1.start()\n",
    "    thread2.start()\n",
    "    \n",
    "    thread1.join()\n",
    "    thread2.join()\n",
    "    \n",
    "    print(f'end value {database_value}')\n",
    "    print('end main')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we are getting correct value now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using Queue for data processing as they are thread safe and processing safe data exchange and data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread, Lock,current_thread\n",
    "from queue import Queue\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "<bound method Queue.empty of <queue.Queue object at 0x7f69d8596748>>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-449ceaba3761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# in threading environemnt when ever you get an object with q.get() after processing call q.taskdone()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_tasks_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfinished_tasks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_tasks_done\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# A Queue is a linear data structure that follows the FIFO or First in First out principle\n",
    "#.e.g. queue of customers in line.\n",
    "if __name__ == '__main__':\n",
    "    q = Queue()\n",
    "    q.put(1)\n",
    "    q.put(2)\n",
    "    q.put(3)\n",
    "    \n",
    "    # 321 --> Front\n",
    "    first=q.get()\n",
    "    print(first)\n",
    "    print(q.empty)\n",
    "    # in threading environemnt when ever you get an object with q.get() after processing call q.taskdone()\n",
    "    q.task_done\n",
    "    q.join()\n",
    "    print('end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(q):\n",
    "    while True:\n",
    "        value=q.get()\n",
    "        #processing\n",
    "        print(f'in {current_thread().name} got {value}')\n",
    "        q.task_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    q = Queue()\n",
    "    num_threads = 10\n",
    "    for i in range(num_threads):\n",
    "        thread = Thread(target=worker, args=(q,))\n",
    "        # daemeon thread-\n",
    "        thread.daemon = True\n",
    "        thread.start()\n",
    "        \n",
    "    for i in range(1,20):\n",
    "        q.put(i)\n",
    "        \n",
    "    q.join()\n",
    "    print('endmain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## daemon thread-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "daemon thread is a background thread that will die when the main thread die. so we ran the while True which is infinite loop as daemon thread and when we ended the main thread these these daemon thread also die. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Value, Array, Lock\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### processes do not live in the same memory space so they dont ave access to public data. Because of that they need special share memory objects to share data.There are two share memory objects-\n",
    "* Value\n",
    "* Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sharing a value\n",
    "def add100(number,lock):\n",
    "    for i in range(100):\n",
    "        time.sleep(0.01)\n",
    "        with lock:\n",
    "            number.value+=1\n",
    "        \n",
    "if __name__==\"__main__\":\n",
    "    shared_number= Value('i',0)\n",
    "    lock = Lock()\n",
    "    print(f'Number at the begining is {shared_number.value}')\n",
    "    p1 = Process(target=add100, args=(shared_number,lock))\n",
    "    p2 = Process(target=add100, args=(shared_number,lock))\n",
    "    \n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    \n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    \n",
    "    print(f'Number at the end is {shared_number.value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array at the begining is [0.0, 100.0, 200.0]\n",
      "array at the end is [2.0, 102.0, 202.0]\n"
     ]
    }
   ],
   "source": [
    "#sharing an array-\n",
    "def add100(number,lock):\n",
    "    for i in range(len(number)):\n",
    "        with lock:\n",
    "            number[i] +=1\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    lock = Lock()\n",
    "    shared_array = Array('d',[0.0,100.0,200.0])\n",
    "    print(f'array at the begining is {shared_array[:]}')\n",
    "    \n",
    "    p1 = Process(target=add100, args=(shared_array,lock))\n",
    "    p2 = Process(target=add100, args=(shared_array,lock))\n",
    "    \n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    \n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    \n",
    "    print(f'array at the end is {shared_array[:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using Queue as process safe data exchange-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "-1\n",
      "-2\n",
      "-3\n",
      "-4\n",
      "-5\n"
     ]
    }
   ],
   "source": [
    "def square(numbers, queue):\n",
    "    for i in numbers:\n",
    "        queue.put(i*i)\n",
    "def make_negative(numbers,queue):\n",
    "    for i in numbers:\n",
    "        queue.put(-1*i)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    numbers = range(1,6)\n",
    "    q=Queue()\n",
    "    \n",
    "    p1 = Process(target=square, args=(numbers,q))\n",
    "    p2 = Process(target=make_negative, args=(numbers,q))\n",
    "    \n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    \n",
    "    \n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    \n",
    "    while not q.empty():\n",
    "        print(q.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A process pool can be used to maintain multiple processes .A process pool object control a pool of workers proccesses to which jobs can be submitted and it can manage the available process for you and split data into small chunks which can then be processed parallel by different processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 8, 27, 64, 125, 216, 343, 512, 729]\n"
     ]
    }
   ],
   "source": [
    "def cube(number):\n",
    "    return number*number*number\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = Pool()\n",
    "    # important pool methods-\n",
    "    # map,apply,join,close\n",
    "    numbers = range(10)\n",
    "    # map it will create processes in your machine to the number of cores available and then split\n",
    "    # the iterable into equal size of chunks and sumbit it to the function.\n",
    "    result = pool.map(cube,numbers)\n",
    "    #apply will execute a process with one value.\n",
    "    pool.apply(cube,numbers[0])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
